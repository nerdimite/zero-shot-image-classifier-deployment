{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6899d17",
   "metadata": {},
   "source": [
    "# Zero Shot Image Classification using CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adequate-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbec0f5",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2c5d0",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "\n",
    "On linux, you can use wget in the terminal to download the pretrained model,\n",
    "```bash\n",
    "wget https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6b5d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'ViT-B-32.pt'\n",
    "model, transformations = clip.load(model_path, device='cpu', jit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca4b951",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d8f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, classes):\n",
    "    \n",
    "    image = transformations(image).unsqueeze(0)\n",
    "    classes = clip.tokenize(classes)\n",
    "\n",
    "    return image, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac7f28",
   "metadata": {},
   "source": [
    "### Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38ebba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: dancing.png\n",
      "1: elon_masked.jpg\n",
      "2: kids_playing.jpg\n",
      "3: plane.jpg\n",
      "4: traffic.jpg\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "images = []\n",
    "for i, file in enumerate(os.listdir('images')):\n",
    "    img_path = os.path.join('images', file)\n",
    "    image_paths.append(img_path)\n",
    "    images.append(Image.open(img_path))\n",
    "    print(f'{i}: {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9173d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"kids playing\", \n",
    "    \"dancing\",\n",
    "    \"elon musk wearing a face mask\", \n",
    "    \"aeroplane\",\n",
    "    \"traffic\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22819658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, classes):\n",
    "\n",
    "    # Preprocess inputs\n",
    "    image_input, classes_input = preprocess(image, classes)\n",
    "\n",
    "    # Forward pass on the model\n",
    "    logits_per_image, logits_per_text = model(image_input, classes_input)\n",
    "\n",
    "    # Normalize the cosine distances using softmax\n",
    "    probs = logits_per_image.softmax(dim=-1).squeeze().tolist()\n",
    "\n",
    "    # Format and sort the final output\n",
    "    output = []\n",
    "    for i, prob in enumerate(probs):\n",
    "        output.append(\n",
    "            (classes[i], round(prob, 4))\n",
    "        )\n",
    "\n",
    "    sorted_outputs = sorted(output, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9533562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: images\\dancing.png\n",
      "Output:\n",
      "[('A photo of dancing', 0.9004), ('A photo of kids playing', 0.0744), ('A photo of aeroplane', 0.0137), ('A photo of elon musk wearing a face mask', 0.0072), ('A photo of traffic', 0.0043)]\n",
      "--------------------------------\n",
      "Input: images\\elon_masked.jpg\n",
      "Output:\n",
      "[('A photo of elon musk wearing a face mask', 1.0), ('A photo of kids playing', 0.0), ('A photo of dancing', 0.0), ('A photo of aeroplane', 0.0), ('A photo of traffic', 0.0)]\n",
      "--------------------------------\n",
      "Input: images\\kids_playing.jpg\n",
      "Output:\n",
      "[('A photo of kids playing', 0.9994), ('A photo of dancing', 0.0005), ('A photo of elon musk wearing a face mask', 0.0), ('A photo of aeroplane', 0.0), ('A photo of traffic', 0.0)]\n",
      "--------------------------------\n",
      "Input: images\\plane.jpg\n",
      "Output:\n",
      "[('A photo of aeroplane', 0.9983), ('A photo of traffic', 0.0016), ('A photo of dancing', 0.0001), ('A photo of kids playing', 0.0), ('A photo of elon musk wearing a face mask', 0.0)]\n",
      "--------------------------------\n",
      "Input: images\\traffic.jpg\n",
      "Output:\n",
      "[('A photo of traffic', 0.9999), ('A photo of kids playing', 0.0), ('A photo of dancing', 0.0), ('A photo of elon musk wearing a face mask', 0.0), ('A photo of aeroplane', 0.0)]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for path, image in zip(image_paths, images):\n",
    "    print(f'Input: {path}')\n",
    "    print('Output:')\n",
    "    print(predict(image, list(map(lambda x: f\"A photo of {x}\", classes))))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5b009",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94547a98",
   "metadata": {},
   "source": [
    "### Test Inference Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc0cb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import CLIPImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f67df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CLIPImageClassifier(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd001a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: images\\dancing.png\n",
      "Output:\n",
      "[('A photo of dancing', 0.9004), ('A photo of kids playing', 0.0744), ('A photo of aeroplane', 0.0137), ('A photo of elon musk wearing a face mask', 0.0072), ('A photo of traffic', 0.0043)]\n",
      "--------------------------------\n",
      "Input: images\\elon_masked.jpg\n",
      "Output:\n",
      "[('A photo of elon musk wearing a face mask', 1.0), ('A photo of kids playing', 0.0), ('A photo of dancing', 0.0), ('A photo of aeroplane', 0.0), ('A photo of traffic', 0.0)]\n",
      "--------------------------------\n",
      "Input: images\\kids_playing.jpg\n",
      "Output:\n",
      "[('A photo of kids playing', 0.9994), ('A photo of dancing', 0.0005), ('A photo of elon musk wearing a face mask', 0.0), ('A photo of aeroplane', 0.0), ('A photo of traffic', 0.0)]\n",
      "--------------------------------\n",
      "Input: images\\plane.jpg\n",
      "Output:\n",
      "[('A photo of aeroplane', 0.9983), ('A photo of traffic', 0.0016), ('A photo of dancing', 0.0001), ('A photo of kids playing', 0.0), ('A photo of elon musk wearing a face mask', 0.0)]\n",
      "--------------------------------\n",
      "Input: images\\traffic.jpg\n",
      "Output:\n",
      "[('A photo of traffic', 0.9999), ('A photo of kids playing', 0.0), ('A photo of dancing', 0.0), ('A photo of elon musk wearing a face mask', 0.0), ('A photo of aeroplane', 0.0)]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for path, image in zip(image_paths, images):\n",
    "    print(f'Input: {path}')\n",
    "    print('Output:')\n",
    "    print(classifier.predict(image, list(map(lambda x: f\"A photo of {x}\", classes))))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4675e",
   "metadata": {},
   "source": [
    "### 1. Initialize Hub API Project\n",
    "Open a terminal and run the following command,\n",
    "```\n",
    "hub init clip-classifier\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82db4ed",
   "metadata": {},
   "source": [
    "### 2. Integration\n",
    "\n",
    "#### i. Copy the files from `model_files/` to `clip-classifier/model/` folder in Hub API project\n",
    "\n",
    "#### ii. Replace the `clip-classifier/src/main.py` code with this,\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "# Add your own import statements\n",
    "from inference import CLIPImageClassifier\n",
    "\n",
    "# This environment variable gives you the\n",
    "# path to the directory of your model. You\n",
    "# can use this in your code to load model\n",
    "# and other large files\n",
    "MODEL_DIR = os.getenv(\"MODEL_DIR\")\n",
    "classifier = CLIPImageClassifier(os.path.join(MODEL_DIR, 'ViT-B-32.pt'))\n",
    "\n",
    "```\n",
    "\n",
    "#### iii. Add the libraries in `zero-shot/src/requirements.txt`\n",
    "```\n",
    "torch\n",
    "clip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed619ba8",
   "metadata": {},
   "source": [
    "### 3. Build and Deploy\n",
    "\n",
    "Change directory into the `clip-classifier` project folder in the terminal and then run the following commands,\n",
    "```bash\n",
    "hub build\n",
    "hub deploy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df8d83",
   "metadata": {},
   "source": [
    "### Test the Deployed API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07ef8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "# Paste your API URL here\n",
    "API_KEY = \"YOUR API KEY HERE\"\n",
    "USERNAME = \"YOUR USERNAME HERE\"\n",
    "API_NAME = \"clip-classifier\" # replace with your project name if you named it anything else other than \"clip-classifier\"\n",
    "\n",
    "# The API endpoint for your Hub API project\n",
    "endpoint = f\"https://api.cellstrathub.com/{USERNAME}/{API_NAME}\"\n",
    "\n",
    "headers = {\n",
    "  \"x-api-key\": API_KEY,\n",
    "  \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42016dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images as base64 encoded strings\n",
    "image_strings = []\n",
    "\n",
    "# Read all the images\n",
    "for img in os.listdir('images'):\n",
    "    img_path = os.path.join('images', img)\n",
    "\n",
    "    if os.path.isfile(img_path):\n",
    "        \n",
    "        # read the image\n",
    "        with open(img_path, 'rb') as f:\n",
    "            img_bytes = f.read()\n",
    "            \n",
    "            # convert to a base64 string\n",
    "            img_str = base64.b64encode(img_bytes).decode('utf-8')\n",
    "            \n",
    "            image_strings.append(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f912dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'image': image_strings[0],\n",
    "    'classes': classes\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(endpoint, headers=headers, data=json.dumps(payload)).json()\n",
    "\n",
    "if response.get('statusCode') == 200:\n",
    "    # Parse the output\n",
    "    body = json.loads(response['body'])\n",
    "    print('Predictions:', json.loads(body['output']))\n",
    "else:\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60fbf1aecf0122793952a73a80d27bc8732eff9e143c13520ca117508929b1c7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('ai': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
